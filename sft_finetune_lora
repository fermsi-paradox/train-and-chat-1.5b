#login to Huggingface account
from huggingface_hub import login
login()

# Import necessary libraries
from transformers.trainer_callback import TrainerCallback
from transformers import AutoModelForCausalLM, AutoTokenizer
from datasets import load_dataset
from trl import SFTConfig, SFTTrainer, setup_chat_format
from peft import LoraConfig
import torch

# Free up memory before loading model
torch.cuda.empty_cache()

#upload dataset from Huggingface
dataset = load_dataset(
    path="<username>/<data>",
    split="train[:10000]"  # Limit initial dataset size for stability
)

device = "cuda" if torch.cuda.is_available() else "cpu"

# Load the model with reduced precision and memory optimizations
model = AutoModelForCausalLM.from_pretrained(
    pretrained_model_name_or_path="<username>/<model>",
    torch_dtype=torch.bfloat16,
    device_map="auto",
    load_in_8bit=True,
    llm_int8_enable_fp32_cpu_offload=True,  # Enable CPU offloading
    use_cache=False #gradient checkpoint warning removal
)

tokenizer = AutoTokenizer.from_pretrained("<username>/<model>")

# Clear existing chat template and set up new chat format
tokenizer.chat_template = None
model, tokenizer = setup_chat_format(model=model, tokenizer=tokenizer)

# Reduced LoRA parameters for stability
peft_config = LoraConfig(
    r=4,                    # Reduced rank dimension
    lora_alpha=8,
    lora_dropout=0.05,
    bias="none",
    target_modules="all-linear",
    task_type="CAUSAL_LM",
)

# Modified training configuration for stability
args = SFTConfig(
    output_dir="<new-model-name>",
    num_train_epochs=1,
    per_device_train_batch_size=1,      # Reduced batch size
    gradient_accumulation_steps=4,      # Increased gradient accumulation
    gradient_checkpointing=True,
    gradient_checkpointing_kwargs={"use_reentrant": False}, #remove warnings
    optim="adamw_torch_fused",
    learning_rate=5e-5,                 # Reduced learning rate
    max_grad_norm=0.3,
    warmup_ratio=0.03,
    lr_scheduler_type="constant",
    logging_steps=5,                    # More frequent logging
    save_strategy="steps",              # Save by steps instead of epochs
    save_steps=100,                     # Save every 100 steps
    bf16=True,
    push_to_hub=True,
    report_to=None,
    max_steps=14580                     # Limit total training steps
)

max_seq_length = 512  # Reduced sequence length

# Initialize trainer with memory optimizations
trainer = SFTTrainer(
    model=model,
    args=args,
    train_dataset=dataset,
    peft_config=peft_config,
    max_seq_length=max_seq_length,
    tokenizer=tokenizer,
    packing=True,
    dataset_kwargs={
        "add_special_tokens": False,
        "append_concat_token": False,
    },
)

class GradientClippingCallback(TrainerCallback):
    def on_step_end(self, args, state, control, **kwargs):
        if hasattr(args, "max_grad_norm") and args.max_grad_norm > 0:
            torch.nn.utils.clip_grad_norm_(kwargs["model"].parameters(), args.max_grad_norm)

# Add gradient clipping
trainer.add_callback(GradientClippingCallback())

# Training with error handling
try:
    trainer.train()
    trainer.save_model()
except Exception as e:
    print(f"Training error: {e}")
    # Save checkpoint if possible
    try:
        trainer.save_model("checkpoint-error")
    except:
        print("Could not save checkpoint after error")
